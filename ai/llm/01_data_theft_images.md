# TITLE: data-theft prompts in downscaled images
## SUMMARY
Researchers have developed a novel attack that steals user data by injecting malicious prompts in images processed by AI systems before delivering them to a large language model.
## REMEDIATION OPTIONS
#### OPTION 1
AI systems implement dimension restrictions when users upload an image. If downscaling is necessary, they advise providing users with a preview of the result delivered to the large language model (LLM).
## REFERENCES
|Description|Reference|
|----|----|
|Link to attack description|[Experiment](https://www.bleepingcomputer.com/news/security/new-ai-attack-hides-data-theft-prompts-in-downscaled-images/)|
